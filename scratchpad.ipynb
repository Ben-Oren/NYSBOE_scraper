{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "proved-catering",
   "metadata": {},
   "source": [
    "# Scratchpad notes for scraping NYS BOE contributions site\n",
    "\n",
    "## Site being scraped\n",
    "https://publicreporting.elections.ny.gov/Contributions/Contributions\n",
    "\n",
    "## Scrapy Commands\n",
    "### Start scrapy shell in terminal to explore above site\n",
    "scrapy shell https://publicreporting.elections.ny.gov/Contributions/Contributions\n",
    "\n",
    "### Xpath command notes while using above in terminal outside notebook\n",
    "#### First mandatory field: Search by\n",
    "response.xpath('/html/body/div[2]/section/form/div[2]/div[3]/div/div/div[5]/div[3]/select/option[2]/text()').getall()\n",
    "\n",
    "returns ['Candidate']\n",
    "\n",
    "for 2:5 in the number after `option`:\n",
    "- `Candidate`\n",
    "- `Commitee`\n",
    "- `Contributor`\n",
    "- `Office`\n",
    "\n",
    "which is all the options, sweet\n",
    "\n",
    "\n",
    "#### Options in mandatory field `office`\n",
    "\n",
    "`Office` seems to have the smallest / least changing number of options\n",
    "\n",
    "for completeness' sake, this is the xpath for the \"search by office\" option from above:\n",
    "response.xpath('/html/body/div[2]/section/form/div[2]/div[3]/div/div/div[5]/div[3]/select/option[5]/text()').getall()\n",
    "\n",
    "\n",
    "### `POST` Snag\n",
    "Looks like there are `POST` requests to different sites for different drop-down toggles?\n",
    "\n",
    "For example:\n",
    "selecting `Office` in `Search by` field generates `POST` request to https://publicreporting.elections.ny.gov/Contributions/GetOfficeByOffType\n",
    "\n",
    "\n",
    "selecting an office in the `Office` drop-down generates `POST` request to https://publicreporting.elections.ny.gov/Contributions/GetFilersByOffice\n",
    "\n",
    "selecting an individual candidate in the `Candidate` drop-down generates `POST` request to https://publicreporting.elections.ny.gov/Contributions/GetCommitteeNameForAuthCand\n",
    "\n",
    "clicking search generates two `POST` requests:\n",
    "https://publicreporting.elections.ny.gov/Contributions/BindContributionsData\n",
    "https://publicreporting.elections.ny.gov/Contributions/GetTotalContrAmount\n",
    "\n",
    "The latter looks like it generates the total contributed amount which is in text above the resulting data table\n",
    "\n",
    "So: try `POST`ing info to the `BindContributionsData` URL?\n",
    "\n",
    "#### Breaking down step by step\n",
    "\n",
    "First, selecting `Office` in the `Search by` field generates a `POST` response to https://publicreporting.elections.ny.gov/Contributions/GetOfficeByOffType\n",
    "\n",
    "By copying the JSON of that `POST` request and feeding it back into https://publicreporting.elections.ny.gov/Contributions/GetOfficeByOffType, we get JSON of the options of offices to select\n",
    "\n",
    "In scrapy shell:\n",
    "```\n",
    "url = 'https://publicreporting.elections.ny.gov/Contributions/GetOfficeByOffType'\n",
    "\n",
    "#dictionary is copied JSON from inspector, GetOfficeByOffType\n",
    "office_payload = {\"lstUCOfficeType\":\"0\",\"lstUCCounty\":\"\",\"lstUCMuncipality\":\"\"}\n",
    "\n",
    "req = FormRequest(url, formdata=office_payload)\n",
    "\n",
    "fetch(req)\n",
    "\n",
    "data = json.loads(response.body)\n",
    "```\n",
    "\n",
    "data is now a list of dictionaries of options to select for `Office`, eg\n",
    "\n",
    "```\n",
    "[{'Selected': False, 'Text': 'Alt Judicial Del. - State', 'Value': '17'},\n",
    " {'Selected': False, 'Text': 'Attorney General - State', 'Value': '7'},\n",
    " ...  \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "received-reasoning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-17 19:17:46 [scrapy.utils.log] INFO: Scrapy 2.4.1 started (bot: scrapybot)\n",
      "2021-03-17 19:17:46 [scrapy.utils.log] INFO: Versions: lxml 4.6.2.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.2.0, Python 3.8.8 (default, Feb 24 2021, 13:46:16) - [Clang 10.0.0 ], pyOpenSSL 20.0.1 (OpenSSL 1.1.1j  16 Feb 2021), cryptography 3.4.6, Platform macOS-10.13.6-x86_64-i386-64bit\n",
      "2021-03-17 19:17:46 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor\n",
      "2021-03-17 19:17:46 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'DUPEFILTER_CLASS': 'scrapy.dupefilters.BaseDupeFilter',\n",
      " 'LOGSTATS_INTERVAL': 0}\n",
      "2021-03-17 19:17:46 [scrapy.extensions.telnet] INFO: Telnet Password: cd11b7629c6c733d\n",
      "2021-03-17 19:17:46 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.memusage.MemoryUsage']\n",
      "2021-03-17 19:17:46 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2021-03-17 19:17:46 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2021-03-17 19:17:46 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2021-03-17 19:17:46 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
      "2021-03-17 19:17:46 [scrapy.core.engine] INFO: Spider opened\n",
      "2021-03-17 19:17:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://publicreporting.elections.ny.gov/Contributions/Contributions> (referer: None)\n",
      "2021-03-17 19:17:48 [asyncio] DEBUG: Using selector: KqueueSelector\n",
      "[s] Available Scrapy objects:\n",
      "[s]   scrapy     scrapy module (contains scrapy.Request, scrapy.Selector, etc)\n",
      "[s]   crawler    <scrapy.crawler.Crawler object at 0x112efb6d0>\n",
      "[s]   item       {}\n",
      "[s]   request    <GET https://publicreporting.elections.ny.gov/Contributions/Contributions>\n",
      "[s]   response   <200 https://publicreporting.elections.ny.gov/Contributions/Contributions>\n",
      "[s]   settings   <scrapy.settings.Settings object at 0x112efbfd0>\n",
      "[s]   spider     <DefaultSpider 'default' at 0x1134e4ee0>\n",
      "[s] Useful shortcuts:\n",
      "[s]   fetch(url[, redirect=True]) Fetch URL and update local objects (by default, redirects are followed)\n",
      "[s]   fetch(req)                  Fetch a scrapy.Request and update local objects \n",
      "[s]   shelp()           Shell help (print this help)\n",
      "[s]   view(response)    View response in a browser\n",
      "2021-03-17 19:17:48 [asyncio] DEBUG: Using selector: KqueueSelector\n",
      "\u001b[?1l\u001b[6n\u001b[?2004h\u001b[?25l\u001b[0m\u001b[?7l\u001b[0m\u001b[J\u001b[0;38;5;28mIn [\u001b[0;92;1m1\u001b[0;38;5;28m]: \u001b[8D\u001b[8C\u001b[?7h\u001b[0m\u001b[?12l\u001b[?25h\u001b[8D\u001b[J\u001b[0m\u001b[?7h\u001b[?2004l\u001b[?1lWARNING: your terminal doesn't support cursor position requests (CPR).\n",
      "\u001b[?2004h\u001b[?25l\u001b[0m\u001b[?7l\u001b[0m\u001b[J\u001b[0;38;5;28mIn [\u001b[0;92;1m1\u001b[0;38;5;28m]: \u001b[8D\u001b[8C\u001b[?7h\u001b[0m\u001b[?12l\u001b[?25h\u001b[?25l\u001b[?7l\u001b[8D\u001b[0m\u001b[J\u001b[0;38;5;28mIn [\u001b[0;92;1m1\u001b[0;38;5;28m]: \u001b[8D\u001b[0m\n",
      "\u001b[J\u001b[?7h\u001b[0m\u001b[?12l\u001b[?25h\u001b[?2004l\n",
      "\u001b[?1l\u001b[?2004h\u001b[?25l\u001b[0m\u001b[?7l\u001b[0m\u001b[J\u001b[0;38;5;28mIn [\u001b[0;92;1m1\u001b[0;38;5;28m]: \u001b[8D\u001b[8C\u001b[?7h\u001b[0m\u001b[?12l\u001b[?25h\u001b[?25l\u001b[?7l\u001b[?7h\u001b[0m\u001b[?12l\u001b[?25h"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clinical-bahamas",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nysboe_scraper",
   "language": "python",
   "name": "nysboe_scraper"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
